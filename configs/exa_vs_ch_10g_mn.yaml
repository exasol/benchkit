title: "Exasol vs ClickHouse Multinode Performance Comparison on TPC-H SF10"
author: "Oleksandr Kozachuk, Principal Architect at Exasol AG"

# Execution configuration (optional)
execution:
  parallel: true          # Enable parallel execution of systems (default: false)
  max_workers: 3          # Max concurrent systems (default: number of systems)

env:
  mode: "aws"                    # aws, gcp, azure, or local
  region: "eu-west-1"
  allow_external_database_access: true  # Allow external access to database ports
  # Instance configuration per system
  instances:
    exasol:
      instance_type: "r5d.xlarge"  # 4 vCPUs, 32GB RAM, 1x150GB NVMe local storage (4 nodes = 128GB total)
      disk:
        type: "local"
      label: "ok-bench-exa-mn"
    clickhouse:
      instance_type: "r5d.xlarge"  # 4 vCPUs, 32GB RAM, 1x150GB NVMe local storage (4 nodes = 128GB total)
      disk:
        type: "local"
      label: "ok-bench-ch-mn"
    clickhouse_tuned:
      instance_type: "r5d.xlarge"  # 4 vCPUs, 32GB RAM, 1x150GB NVMe local storage (4 nodes = 128GB total)
      disk:
        type: "local"
      label: "ok-bench-ch-tuned-mn"
  os_image: "ubuntu-22.04"
  ssh_key_name: "ok-work3"            # AWS key pair name (without .pem extension)
  ssh_private_key_path: "~/.ssh/ok-work3.pem"  # Local private key file path

systems:
  # Baseline: Exasol with original queries (first system is baseline)
  - name: "exasol"
    kind: "exasol"
    version: "2025.1.0"          # Latest Exasol version
    setup:
      method: "installer"        # Native c4 installation
      node_count: 4              # 4-node cluster
      use_additional_disk: true  # Auto-detect and use additional NVMe disk
      c4_version: "4.28.2"       # Latest c4 version
      host_addrs: "$EXASOL_PRIVATE_IP"  # Will be resolved from infrastructure
      host_external_addrs: "$EXASOL_PUBLIC_IP"
      image_password: "exasol123"
      db_password: "exasol456"
      admin_password: "exasol789"
      working_copy: "@exasol-2025.1.0"
      license_file: "configs/exasol.license"  # License file path
      extra:
        dbram: "12g"             # Database RAM allocation per node (4 nodes × 12g = 48g total)
        optimizer_mode: "analytical"
        # Exasol database parameters for analytical workload optimization
        db_params:
          - "-writeTouchInit=1"
          - "-cacheMonitorLimit=0"
          - "-maxOverallSlbUsageRatio=0.95"
          - "-useQueryCache=0"
          - "-query_log_timeout=0"
          - "-joinOrderMethod=0"
          - "-etlCheckCertsDefault=0"

  # ClickHouse with original queries
  - name: "clickhouse"
    kind: "clickhouse"
    version: "25.10.2.65"         # Latest stable ClickHouse version
    setup:
      method: "native"           # Native APT installation
      node_count: 4              # 4-node cluster
      use_additional_disk: true  # Auto-detect and use additional NVMe disk
      data_dir: "/data/clickhouse"
      host: "$CLICKHOUSE_PUBLIC_IP"  # Use public IP for external access
      port: 8123                 # HTTP port for clickhouse-connect
      username: "default"
      password: "clickhouse123"  # Password for benchmark user
      extra:
        memory_limit: "12g"      # Memory limit per node (4 nodes × 12g = 48g total)
        max_threads: "4"         # Match instance vCPUs per node
        max_memory_usage: "11000000000"  # ~10.5GB in bytes per node

  # ClickHouse with tuned queries
  - name: "clickhouse_tuned"
    kind: "clickhouse"
    version: "25.10.2.65"         # Latest stable ClickHouse version
    setup:
      method: "native"           # Native APT installation
      node_count: 4              # 4-node cluster
      use_additional_disk: true  # Auto-detect and use additional NVMe disk
      data_dir: "/data/clickhouse"
      host: "$CLICKHOUSE_TUNED_PUBLIC_IP"  # Use public IP for external access
      port: 8123                 # HTTP port for clickhouse-connect
      username: "default"
      password: "clickhouse123"  # Password for benchmark user
      extra:
        memory_limit: "12g"      # Memory limit per node (4 nodes × 12g = 48g total)
        max_threads: "4"         # Match instance vCPUs per node
        max_memory_usage: "11000000000"  # ~10.5GB in bytes per node

workload:
  name: "tpch"
  scale_factor: 10              # 10GB dataset
  runs_per_query: 7             # Number of measured runs
  warmup_runs: 1                # Warmup runs before measurement
  data_format: "csv"            # csv or parquet
  generator: "dbgen"
  system_variants:
    clickhouse_tuned: "tuned"   # ClickHouse-tuned uses tuned queries

report:
  show_boxplots: true
  show_latency_cdf: true
  show_bar_chart: true
  show_heatmap: true
